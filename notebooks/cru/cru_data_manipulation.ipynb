{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python example for Climatic Research Unit (CRU) time-series (TS) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRU TS data\n",
    "\n",
    "The following guide will assist with the manipulation of the Climatic Research Unit (CRU) gridded time-series (TS) dataset. For more information on this data, or to understand the ways in which it can be downloaded, please see the CEDA CRU data user guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is put at the beginning of the script to add the specific packages (tools) that are needed in python to achieve the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation of temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read in the data to the program so it can be viewed, manipulated and displayed as required. The text within the quotation marks is the file path. As we know the data is on the CEDA Archive, we can read it directly from the path we used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/badc/cru/data/cru_ts/cru_ts_4.02/data/tmp/cru_ts4.02.1901.2017.tmp.dat.nc\"\n",
    "data = netCDF4.Dataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand a bit more about what's inside the NetCDF file, you can print the variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['lon', 'lat', 'time', 'tmp', 'stn'])\n"
     ]
    }
   ],
   "source": [
    "print(data.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .keys() method provides only the variable names, without this you will get additional metadata. Each dimension in the file also has a variable, so you will see a variable for each dimension, in this case:\n",
    "<ul>\n",
    "<li>'lat' for latitudes<\\li>\n",
    "<li>'lon' for longitudes<\\li>\n",
    "<li>'time' for time<\\li><\\li>\n",
    "<li>'tmp' for near surface temperature<\\li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the temperature, longitude, latitude and time variables are set. This allows the temperature data to be used within the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.variables['tmp'][:]\n",
    "lon = data.variables['lon'][:]\n",
    "lat = data.variables['lat'][:]\n",
    "time = data.variables['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Climatology - global temperature data averaged over time (1901-2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature variable that has been set as 'temp' in the code above, is a function of latitude, longitude and time as it is 3-dimensional. To produce a map plot, the temperature values need to be averaged across the entire time period of the dataset. This will give 1 average value per grid point. The line below averages the temperature variable by the time axis. You could pick specific years that you want to view by subsetting the data, the below is similar to the climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_av_1901_2017= np.mean(temp[:,:,:],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Global temperature anomaly of 2017 (with respect to 1961-1990 reference period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below slices the temperature data so we now have the temperature data between 1961 and 1990 and the temperature data for just 2017 only. This allows us to calculate a 2017 anomaly value, compared to our reference period (1961-1990). Firstly, we will use a time conversion to more easily identify the index values we need to slice the data with to obtain 2017 (the same can be done to find 1961-1990 or any other year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 1, 16, 0, 0) datetime.datetime(2017, 2, 15, 0, 0)\n",
      " datetime.datetime(2017, 3, 16, 0, 0) datetime.datetime(2017, 4, 16, 0, 0)\n",
      " datetime.datetime(2017, 5, 16, 0, 0) datetime.datetime(2017, 6, 16, 0, 0)\n",
      " datetime.datetime(2017, 7, 16, 0, 0) datetime.datetime(2017, 8, 16, 0, 0)\n",
      " datetime.datetime(2017, 9, 16, 0, 0)\n",
      " datetime.datetime(2017, 10, 16, 0, 0)\n",
      " datetime.datetime(2017, 11, 16, 0, 0)\n",
      " datetime.datetime(2017, 12, 16, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "time_convert = netCDF4.num2date(time[:], time.units, time.calendar)\n",
    "print(time_convert[1392:1404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1961_1990 = np.mean(temp[720:1080,:,:],axis = 0)\n",
    "\n",
    "temp_2017 = np.mean(temp[1392:1404,:,:],axis=0)\n",
    "\n",
    "temp_2017_anom = temp_2017 - temp_1961_1990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Annual mean temperature anomaly averaged globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a global time series graph, the data needs to be averaged in a different way. To create a time series plot, the data needs to be averaged across all grid points, so there is 1 global average value vs time. The line of code below does exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average= np.mean(temp[:,:,:],axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the seasonal noise, an annual average needs to be calculated from the monthly data. The code below reshapes the global average into [117,12] as there are 117 years in the dataset, each with 12 months. Then the average is calculated for each year. These new annual average values are saved as 'annual_temp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_temp = np.mean(np.reshape(global_average, (117,12)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to look at the temperature values as an anomaly compared to a certain temperature period. The following code calculates the annual temperature anomaly in comparison to the average temperature in 1961-1990. The first line calculates the average temperature value for this time period (1961-1990). This is done by slicing the data with the indices 60:89 as this gives the values from 1961-1990, then averaging these values. The second line then deducts the average temperature value between 1961-1990 from each of the annual temperature values calculated above, saving it as 'temp_anomaly'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_1961_1990=np.mean(annual_temp[60:90])\n",
    "\n",
    "temp_anomaly = annual_temp - av_1961_1990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation of precipitation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extracting a spatial subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use precipitation data. We can see that in the archive using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/badc/cru/data/cru_ts/cru_ts_4.02/data/pre/cru_ts4.02.1901.2017.pre.dat.nc\n"
     ]
    }
   ],
   "source": [
    "! ls /badc/cru/data/cru_ts/cru_ts_4.02/data/pre/cru_ts4.02.1901.2017.pre.dat.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python we will now read in precipitation data and subset the data to obtain Europe region only.There are many different ways to obtain a regional subset of the data. This is just one method.\n",
    "\n",
    "First we read in the precipitation data and name variables as we have done before.\n",
    "\n",
    "In order to create a regional subset, specifically Europe here, the code below sets latitude (lat_bnds) and longitude (lon_bnds) boundaries (range). These boundaries are then used to identify the index within the precipitation data.\n",
    "\n",
    "When we select this data (pre), we slice the latitude and longitude values using our boundaries for Europe. This ensures the precipitation data is restricted to only the area we want. So this data can be exported to a csv file we are only going to abstract 1 month of data. Within the final line of code, weare slicing the data for 1 month - Jan 1901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_ds = netCDF4.Dataset('/badc/cru/data/cru_ts/cru_ts_4.02/data/pre/cru_ts4.02.1901.2017.pre.dat.nc')\n",
    "\n",
    "latitude = rain_ds.variables['lat'][:]\n",
    "longitude = rain_ds.variables['lon'][:]\n",
    "\n",
    "lat_bnds, lon_bnds = [35, 70], [-10, 30]\n",
    "\n",
    "lat_index = np.where((latitude > lat_bnds[0]) & (latitude < lat_bnds[1]))[0]\n",
    "lon_index = np.where((longitude > lon_bnds[0]) & (longitude < lon_bnds[1]))[0]\n",
    "\n",
    "rain = rain_ds.variables['pre']\n",
    "\n",
    "rain_eu = rain[0, lat_index, lon_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting a temporal subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to some of the data manipulation we have done previously.\n",
    "\n",
    "Using the precipitation data from above, the code below calculates the average rainfall in 2017 (Jan-Dec) for the whole globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_2017 = np.mean(rain[1392:1404,:,:],axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
