{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACI data files explained\n",
    "<i>Maxim Chernetskiy, Mathias Disney 2018<br>\n",
    "WP2 Consistent EO datasets across space, time and wavelength</i>\n",
    "<br><br><br>\n",
    "This document explains basics of opening and manipulation of the BACI Surface State Vector (SSV) files in netCDF format. SSV consists of surface reflectance, albedo, land surface temperature (LST) and synthetic apperture radar (SAR) backscatter. All datasets have the same spatial resolution, geographical projection and temporal step. Presented examples are based on the following python 2.7 libraries:<br>\n",
    "    netCDF4 - working with python netCDF;<br>\n",
    "    GDAL - Geospatial Data Abstraction Library;<br>\n",
    "    seaborn - enhanced data visualization and<br>\n",
    "    scikit-learn - machine learning library.<br>\n",
    "    \n",
    "Datasets can be found in the CEDA archive <i>/neodc/baci_ssv/data/v1.0/</i><br>\n",
    "You can find more information on these data sets in the CEDA catalogue <a href=\"https://catalogue.ceda.ac.uk/uuid/1452fa13390549f5a6794840b948a8d1 \"\n",
    "All regional sites which are in the geographical Europe are in the same folder <i>/group_workspaces/jasmin2/baci/sigil/baci_wp2_files/13_europe/</i><br>\n",
    "Datasets are in sinusoidal projection and divided by MODIS tiles <a href=\"https://modis-land.gsfc.nasa.gov/MODLAND_grid.html\">https://modis-land.gsfc.nasa.gov/MODLAND_grid.html</a>\n",
    "This means that processed regions are larger than BACI regional sites.\n",
    "<br>\n",
    "Table of Contents:\n",
    "<br>\n",
    "    1. Opening and reading\n",
    "    1.1 Optical data\n",
    "    1.2 Land Surface Temperature (LST)\n",
    "    1.3 Synthetic Apperture Radar (SAR) backscatter\n",
    "    2. Reprojection\n",
    "    3. Principal Componenet Analysis (PCA)\n",
    "    4. Clustering\n",
    "    4.1 Red and NIR\n",
    "    4.2 Red, NIR and LST\n",
    "    4.3 Red, NIR, LST and micowave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import virtualenv\n",
    "import pip\n",
    "import os\n",
    "print(\"hello again\")\n",
    "# Define and create the base directory install virtual environments\n",
    "venvs_dir = os.path.join(os.path.expanduser(\"~\"), \"nb-venvs\")\n",
    "# Create base venvs directory if not already there\n",
    "if not os.path.isdir(venvs_dir):\n",
    "    os.makedirs(venvs_dir)\n",
    "# Define the venv directory\n",
    "venv_dir = os.path.join(venvs_dir, 'venv-notebook')\n",
    "if not os.path.isdir(venv_dir):\n",
    "    # Create the virtual environment\n",
    "    print(f'[INFO] Creating: virtual env at: {venv_dir}')\n",
    "    virtualenv.create_environment(venv_dir)\n",
    "# Activate the venv\n",
    "activate_file = os.path.join(venv_dir, \"bin\", \"activate_this.py\")\n",
    "exec(open(activate_file).read(), dict(__file__=activate_file))\n",
    "# Try to import seaborn, if it fails, then try to pip install it,\n",
    "# and import again\n",
    "try:\n",
    "    import seaborn\n",
    "except Exception as exc:\n",
    "    # pip install a package using the venv as a prefix\n",
    "    print(f'[INFO] Pip installing \"seaborn\"')\n",
    "    pip.main([\"install\", \"--prefix\", venv_dir, \"seaborn\"])\n",
    "    import seaborn\n",
    "print(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "print(\"nice day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Opening and reading\n",
    "### 1.1 Optical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, open a netcdf file with the netCDF4 library function Dataset() which opens file returns a netcdf dataset. You have to specify your own path to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nc.Dataset('/neodc/baci_ssv/data/v1.0/regional_sites/13_europe/optical/rho_h18v04_2015_7day.nc')\n",
    "print(\"got my file now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what is inside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some variables and two groups: reflectance and albedo. The meaning of groups is combining some variables together in order to make netcdf more structured. Now let's examine the variables. <br>\n",
    "Dates are represented as julian dates which are days since January 1, 4713 BC. If we print the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['julday'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that almost two and half million days are passed since starting date <br>\n",
    "This form of representation is usefull but not super convinient for humans. So we can convert julian days to \"normal\" date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as dates\n",
    "date_arr = []\n",
    "for jd in ds['julday'][:]: \n",
    "    date_arr.append(dates.num2date(dates.julian2num(jd)).date())\n",
    "date_arr = np.array(date_arr)\n",
    "print([d.isoformat() for d in date_arr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next couple of variables are latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['lat'])\n",
    "print (ds['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that geographical coordinates are saved as two dimensional arrays with 1200X1200 pixels in each. If it's 2D array we can show an image of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Lat')\n",
    "# This the main function in showing an image. Imshow - image show. Here it simply shows a 2D array.\n",
    "plt.imshow(ds['lat'], cmap = plt.set_cmap('Blues'))\n",
    "plt.colorbar(fraction=0.046, pad=0.03)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Lon')\n",
    "plt.imshow(ds['lon'])\n",
    "plt.colorbar(fraction=0.046, pad=0.03)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last variable with out group is CRS which is a representation of geographical projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['crs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groups 'reflectance' and 'albedo' are the combination of variables which relate to reflectance and albedo. This is the main thing in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['reflectance'])\n",
    "print(ds['albedo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that varialbes in these groups have three dimentions i.e. date, x and y. The dimentionality of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ds['reflectance/refl_b2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the temporal step is seven days + we can have some missing data. So first dimention is equal to 49. If we look at variable 'julday':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ds['julday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot NIR band\n",
    "\n",
    "Use interactive mode (%matplotlib notebook) to find coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds['reflectance/refl_b2'][0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch from interactive mode to normal show a point which was just found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ****************\n",
    "x = 1033; y = 893\n",
    "# ****************\n",
    "plt.imshow(ds['reflectance/refl_b2'][0,:,:])\n",
    "plt.plot(x, y, marker='o', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show temporal prifile of the point. Note that in python arrays coordinate 'y' is the first dimension and 'x' the seond!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the same size as the first dimention of reflectance. Therefore we can use it to plot temporal evelution of the data along with associated uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = ds['reflectance/refl_b2'][:, y, x]\n",
    "rho_sd = ds['reflectance/refl_b2_sd'][:, y, x]\n",
    "\n",
    "plt.fill_between(ds['julday'], rho + rho_sd, rho - rho_sd, color='0.8')\n",
    "plt.plot(ds['julday'], rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show seven reflectance bands for the first date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_refl(var, vmin=0, vmax=1):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for b in range(7):\n",
    "        plt.subplot(2, 4, b + 1)\n",
    "        plt.title('band %d' % (b+1))\n",
    "        plt.imshow(ds[var % (b+1)][0,:,:], vmin=vmin, vmax=vmax, cmap=plt.set_cmap('gray'))\n",
    "        plt.colorbar(fraction=0.046, pad=0.03)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refl('reflectance/refl_b%d', vmin=0, vmax=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we can show uncertainties in each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refl('reflectance/refl_b%d_sd', vmin=0, vmax=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group in the netcdf reflectance file is albedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_albedo(var, vmin=0, vmax=1):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    bands = ['vis', 'nir', 'swir']\n",
    "    for b in range(3):\n",
    "        plt.subplot(2, 4, b + 1)\n",
    "        plt.title('%s' % bands[b])\n",
    "        plt.imshow(ds[var % bands[b]][0,:,:], vmin=vmin, vmax=vmax, cmap=plt.set_cmap('gray'))\n",
    "        plt.colorbar(fraction=0.046, pad=0.03)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_albedo('albedo/albedo_%s', vmin=0, vmax=0.4)\n",
    "plot_albedo('albedo/albedo_%s_sd', vmin=0, vmax=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show a RGB image as three dimentional array where each dimention is a color componenet. For example true color composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = np.zeros((1200, 1200, 3))\n",
    "img_rgb[:, :, 0] = ds['reflectance/refl_b1'][0,:,:] * 5\n",
    "img_rgb[:, :, 1] = ds['reflectance/refl_b4'][0,:,:] * 5\n",
    "img_rgb[:, :, 2] = ds['reflectance/refl_b3'][0,:,:] * 5\n",
    "plt.imshow(img_rgb)\n",
    "# plt.colorbar(fraction=0.046, pad=0.03)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Land Surface Temperature (LST)\n",
    "Open and show the LST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_lst = nc.Dataset('/neodc/baci_ssv/data/v1.0/regional_sites/13_europe/lst/lst_h18v04_2015_7day.nc')\n",
    "ds_lst = nc.Dataset('/neodc/baci_ssv/data/v1.0/regional_sites/13_europe/lst/lst_h18v04_2015_7day.nc')\n",
    "print(ds_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ds_lst['lst'][:, y, x]\n",
    "lst_sd = ds_lst['lst_sd'][:, y, x]\n",
    "\n",
    "plt.fill_between(ds_lst['time'], lst + lst_sd, lst - lst_sd, color='0.8')\n",
    "plt.plot(ds_lst['time'], lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('LST')\n",
    "plt.imshow(ds_lst['lst'][0,:,:], cmap=plt.set_cmap('hot'))\n",
    "plt.colorbar(fraction=0.046, pad=0.03, label='Temperature, K')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('LST uncertainty')\n",
    "plt.imshow(ds_lst['lst_sd'][0,:,:], vmin=0, vmax=5)\n",
    "plt.colorbar(fraction=0.046, pad=0.03, label='Temperature, K')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Synthetic Apperture Radar (SAR) backscatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sar = nc.Dataset('/neodc/baci_ssv/data/v1.0/regional_sites/13_europe/sar/sentinel-1_descending_h18v04_2015_7day_vv.nc')\n",
    "print(ds_sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 1000\n",
    "# y = 800\n",
    "\n",
    "sar = ds_sar['bs'][:, y, x]\n",
    "\n",
    "sar_sd = ds_sar['bs_sd'][:, y, x]\n",
    "\n",
    "plt.fill_between(ds_sar['julday'], sar + sar_sd, sar - sar_sd, color='0.8')\n",
    "plt.plot(ds_sar['julday'], sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Backscatter')\n",
    "plt.imshow(ds_sar['bs'][0,:,:], cmap=plt.set_cmap('bone'))\n",
    "plt.colorbar(fraction=0.046, pad=0.03, label='Db')\n",
    "plt.plot(x, y, 'o')\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Backscatter uncertainty')\n",
    "plt.imshow(ds_sar['bs_sd'][0,:,:], vmin=0, vmax=5)\n",
    "plt.colorbar(fraction=0.046, pad=0.03, label='Db')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reprojection\n",
    "<br><br>\n",
    "BACI netCDF files are in the MODIS sinusoidal projection (SR-ORG:6842). Below we can see an example with grid lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_geogrid(img, lat_max, lat_min, lon_max, lon_min, proj, geo):\n",
    "    \"\"\"\n",
    "    Draw grid lines over an image\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isfile('grid_lines.py'):\n",
    "\n",
    "        # Import some additional functions\n",
    "        #from grid_lines import *\n",
    "\n",
    "        # Draw lat-lon grid lines\n",
    "        for lon in xrange(lon_min, lon_max, 2):\n",
    "            x1, y1 = get_pixels(geo, lat_max, lon)\n",
    "            x2, y2 = get_pixels(geo, lat_min, lon)\n",
    "            x1, x2, y1, y2 = find_inter(x1, x2, y1, y2, img.shape[0], img.shape[1])\n",
    "            plt.plot([x1, x2], [y1, y2], c='k')\n",
    "        for lat in xrange(lat_min, lat_max, 2):\n",
    "            x1, y1 = get_pixels(geo, lat, lon_max)\n",
    "            x2, y2 = get_pixels(geo, lat, lon_min)\n",
    "            x1, x2, y1, y2 = find_inter(x1, x2, y1, y2, img.shape[0], img.shape[1])\n",
    "            plt.plot([x1, x2], [y1, y2], c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_max = np.max(ds['lat'])\n",
    "lat_min = np.min(ds['lat'])\n",
    "lon_min = np.min(ds['lon'])\n",
    "lon_max = np.max(ds['lon'])\n",
    "\n",
    "# Get projection and geo-transformation\n",
    "crs_proj = ds['crs'].spatial_ref\n",
    "crs_geo = ds['crs'].GeoTransform\n",
    "\n",
    "# Get first date from the NIR reflectance band\n",
    "# img = ds['reflectance/refl_b2'][0,:,:]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "plt.imshow(ds['reflectance/refl_b2'][0,:,:], vmin=0, vmax=0.6, cmap=plt.set_cmap('gray'))\n",
    "\n",
    "draw_geogrid(ds['reflectance/refl_b2'][0,:,:],\n",
    "             np.round(lat_max).astype(int), \n",
    "             np.round(lat_min).astype(int), \n",
    "             np.round(lon_max).astype(int), \n",
    "             np.round(lon_min).astype(int), \n",
    "             crs_proj, crs_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that in sinusoidal projection geometry can't be described by 1D latitude and longitude vectors. Besides not all GIS software can recognize sinusoidal projection. An example is OpenLayers. In addition not all software can work well (or can't work  at all) with netCDF format. Therefore sometimes it's nesssary to reproject data to WGS 84 (lat-lon, EPSG:4326) and save result in some well known format such as GeoTiff.\n",
    "<br><br>\n",
    "For reprojection and geotiff we need library GDAL - Geospatial Data Abstraction Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdal\n",
    "import gdal, osr\n",
    "\n",
    "\n",
    "# Create empty output file\n",
    "drv_out = gdal.GetDriverByName('GTiff')\n",
    "ds_out = drv_out.Create('baci_wgs84.tif', 1200, 1250, 1, gdal.GDT_Float32)\n",
    "\n",
    "# make output projection\n",
    "wgs84 = osr.SpatialReference()\n",
    "wgs84.ImportFromEPSG(4326)\n",
    "proj_out = wgs84.ExportToWkt()\n",
    "\n",
    "# make geotransformation\n",
    "lon_size = (lon_max - lon_min) / 1200.\n",
    "lat_size = (lat_max - lat_min) / 1200.\n",
    "# 0.01296 0.008\n",
    "geo_out = (np.float(ds['lon'][0,0]), lon_size, 0, np.float(ds['lat'][0,0]), 0, -lat_size)\n",
    "\n",
    "# Setup input geotrasnforamation and projection\n",
    "ds_out.SetGeoTransform(geo_out)\n",
    "ds_out.SetProjection(proj_out)\n",
    "\n",
    "# Create input gdal dataset in memory\n",
    "drv_in = gdal.GetDriverByName('MEM')\n",
    "ds_in = drv_in.Create('', 1200, 1200, 1, gdal.GDT_Float32)\n",
    "\n",
    "# Setup input geotrasnforamation and projection\n",
    "ds_in.SetGeoTransform(crs_geo)\n",
    "ds_in.SetProjection(str(crs_proj))\n",
    "\n",
    "# Write an image from netCDF to input gdal dataset\n",
    "ds_in.GetRasterBand(1).WriteArray(ds['reflectance/refl_b2'][0,:,:])\n",
    "\n",
    "# Do reprojection\n",
    "res = gdal.ReprojectImage(ds_in, ds_out, str(crs_proj), proj_out, gdal.GRA_Average)\n",
    "ds_in = None\n",
    "ds_out = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and show rreprojected geotiff\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ds_out = gdal.Open('baci_wgs84.tif')\n",
    "img_out = ds_out.GetRasterBand(1).ReadAsArray()\n",
    "img_out = np.ma.array(img_out, mask = np.logical_or(img_out>1, img_out==0))\n",
    "plt.imshow(img_out, vmin=0, vmax=0.6)\n",
    "\n",
    "draw_geogrid(img_out,\n",
    "             np.round(lat_max).astype(int), \n",
    "             np.round(lat_min).astype(int), \n",
    "             np.round(lon_max).astype(int), \n",
    "             np.round(lon_min).astype(int), \n",
    "             proj_out, geo_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see an image transformed to WGS84. In this casewe can use 1D arrays of latitude and longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Principal Component Analisys (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows a simple example of using PCA to reveal what is common in the three types of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_lst['time'][1:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PCA, clustering and classification we can use python machine learning library sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as decomp\n",
    "import sklearn.preprocessing as prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use only one pixel for one year. sklearn PCA uses as input a variable X which has shape (n_samples X n_features). In our example we have time series with 49 dates for three microwave domains: optical, temperature and microwave. So we have 49 samples and 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input variable X\n",
    "X = np.zeros((49, 3))\n",
    "\n",
    "# We have data with quite different scales so doing normalization is essential\n",
    "X[:,0] = prep.normalize([rho])\n",
    "X[:,1] = prep.normalize([lst[1:-3]])\n",
    "X[:,2] = prep.normalize([sar[1:-3]])\n",
    "\n",
    "# create an instance of object PCA\n",
    "pca = decomp.PCA()\n",
    "\n",
    "# fit PCA\n",
    "pca.fit(X)\n",
    "\n",
    "# transform the data\n",
    "comp = pca.transform(X)\n",
    "print(comp.shape)\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(141)\n",
    "\n",
    "# plt.subplot(142)\n",
    "# plt.plot(ds_lst['time'], lst)\n",
    "# plt.subplot(143)\n",
    "# plt.plot(ds['julday'], rho)\n",
    "# plt.subplot(144)\n",
    "# plt.plot(ds_lst['time'], sar)\n",
    "tit = ['optical', 'LST', 'SAR']\n",
    "for i in range(3):\n",
    "    plt.subplot(1,4,i+2)\n",
    "    plt.title(tit[i])\n",
    "    plt.plot(X[:, i])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(141)\n",
    "plt.title('Ratio of explained variance')\n",
    "plt.plot(pca.explained_variance_ratio_, marker='o', ls='--')\n",
    "for i in range(3):\n",
    "    plt.subplot(1,4,i+2)\n",
    "    plt.title('PCA %d' % (i+1))\n",
    "    plt.plot(comp[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define correlation function for mapping accross the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc(x, y, **kws):\n",
    "    \"\"\"\n",
    "    Correlation function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-variable for regression\n",
    "    y: y-variable    \n",
    "    \"\"\"\n",
    "    s, i, r, p, sd = stats.linregress(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"$r^2$ = {:.2f}\\n y={:.2f}x+{:.2f}\".format(r, s, i),\n",
    "                xy=(.05, .75), xycoords=ax.transAxes, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do PCA and plot correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'rho': X[:,0], 'lst': X[:,1], 'sar': X[:, 2],\\\n",
    "     'PC1': comp[:,0], 'PC2': comp[:,1], 'PC3': comp[:,2]}\n",
    "# make pandas data frame which is special tabular representation of data\n",
    "df = pd.DataFrame(data=d)\n",
    "# use seaborn library to plot pairwise relationships in data\n",
    "g = sns.pairplot(df, kind='reg')\n",
    "# map correlation coeeficients. I.e. print r2 in corresponding plots\n",
    "g.map_lower(corrfunc)\n",
    "# sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the first principal component explains about 80% of variance and mostly related to backscatter abd NIR reflectance.\n",
    "<br> <br>\n",
    "Sklearn also has other types of PCA: Incremental PCA, Kernel PCA, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the sklearn library for clustering of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Let's open Sentinel-1 ascending orbit backscatter\n",
    "ds_sar_asc = nc.Dataset('/neodc/baci_ssv/data/v1.0/regional_sites/13_europe/sar/sentinel-1_ascending_h18v04_2015_7day_vv.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to increse speed we make a subset from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_red = ds['reflectance/refl_b1'][0, 800:900, 1000:1200].data\n",
    "img_nir = ds['reflectance/refl_b2'][0, 800:900, 1000:1200].data\n",
    "img_lst = ds_lst['lst'][0, 800:900, 1000:1200].data\n",
    "img_sar = ds_sar['bs'][0, 800:900, 1000:1200]\n",
    "img_sar_asc = ds_sar_asc['bs'][0, 800:900, 1000:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign zero to no-data pixels\n",
    "img_red[img_red > 1] = 0\n",
    "img_nir[img_nir > 1] = 0\n",
    "img_lst[img_lst > 1000] = 0\n",
    "\n",
    "myimage = np.unique(img_sar)\n",
    "\n",
    "print(myimage)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "ax=plt.subplot(231)\n",
    "plt.title('Reflectance Red')\n",
    "ax.imshow(img_red, vmin=0, vmax=0.2, cmap=plt.set_cmap('gray'))\n",
    "plt.axis('off')\n",
    "\n",
    "ax=plt.subplot(232)\n",
    "plt.title('Reflectance NIR')\n",
    "ax.imshow(img_nir, vmin=0, vmax=0.5, cmap=plt.set_cmap('gray'))\n",
    "plt.axis('off')\n",
    "\n",
    "ax=plt.subplot(233)\n",
    "plt.title('LST')\n",
    "ax.imshow(img_lst, vmin=260, vmax=300, cmap=plt.set_cmap('hot'))\n",
    "plt.axis('off')\n",
    "\n",
    "ax = plt.subplot(234)\n",
    "plt.title('SAR descending')\n",
    "ax.imshow(img_sar, vmin=-23, vmax=2, cmap=plt.set_cmap('bone'))\n",
    "plt.axis('off')\n",
    "\n",
    "ax = plt.subplot(235)\n",
    "plt.title('SAR ascending')\n",
    "ax.imshow(img_sar_asc, vmin=-23, vmax=2, cmap=plt.set_cmap('bone'))\n",
    "plt.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use popular clustering method K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_clust(Ximg):\n",
    "    \"\"\"\n",
    "    Do clustering and plot the results\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Ximg: array\n",
    "        an array of input values (n_samples X n_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the KMeans object and fit the data\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0).fit(Ximg)\n",
    "    # Predict clusters\n",
    "    km = kmeans.predict(Ximg)\n",
    "    # Reshape array of clusters to originl size of image\n",
    "    img_c = np.reshape(km, (img_red.shape[0], img_red.shape[1]))\n",
    "    # Show results\n",
    "    im = plt.imshow(img_c, cmap=plt.get_cmap('tab10', 5))\n",
    "    plt.colorbar(ticks=range(5), label='Clusters', fraction=0.023, pad=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Red and NIR\n",
    "Firstly we are going to use only optical data from red and NIR bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of input values with shape n_samples x n_features\n",
    "Ximg = np.zeros((img_red.shape[0] * img_red.shape[1], 2))\n",
    "\n",
    "# We have data with quite different scales so doing normalization is essential\n",
    "Ximg[:, 0] = prep.normalize([img_red.flatten()])\n",
    "Ximg[:, 1] = prep.normalize([img_nir.flatten()])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "do_clust(Ximg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Red, NIR and LST\n",
    "On next step let's add temperature for the same date as a new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ximg = np.zeros((img_red.shape[0] * img_red.shape[1], 3))\n",
    "\n",
    "# We have data with quite different scales so doing normalization is essential\n",
    "Ximg[:, 0] = prep.normalize([img_red.flatten()])\n",
    "Ximg[:, 1] = prep.normalize([img_nir.flatten()])\n",
    "Ximg[:, 2] = prep.normalize([img_lst.flatten()])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "do_clust(Ximg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results of clusterias]zation with data of reflectance and LST we can cleary see some lakes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Red, NIR, LST and micowave\n",
    "Add SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ximg = np.zeros((img_red.shape[0] * img_red.shape[1], 5))\n",
    "\n",
    "# We have data with quite different scales so doing normalization is essential\n",
    "Ximg[:, 0] = prep.normalize([img_red.flatten()])\n",
    "Ximg[:, 1] = prep.normalize([img_nir.flatten()])\n",
    "Ximg[:, 2] = prep.normalize([img_lst.flatten()])\n",
    "Ximg[:, 3] = prep.normalize([img_sar.flatten()])\n",
    "Ximg[:, 4] = prep.normalize([img_sar_asc.flatten()])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "do_clust(Ximg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new information that have been added to results is separation of lakes with shallow waters (right hand side of the image) and more deep waters (left hand side). This kind of information can't be detected by optical data. At the same time we can see some patterns related vegetation which can't be clearly seen by a microwave sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
